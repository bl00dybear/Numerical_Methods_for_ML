                   Calcul Numeric
                     Laboratorul 3.
             Descompunerea Valorilor Singulare



1     Descompunerea valorilor singulare
Pentru orice matrice A âˆˆ RmÃ—n existaÌ† matricile ortogonale U âˆˆ RmÃ—m s, i
V âˆˆ RnÃ—n astfel Ä±Ì‚ncaÌ‚t

                                     A = U SV >                                      (1)
unde S âˆˆ RmÃ—n este o matrice diagonalaÌ† avaÌ‚nd r elemente nenule, unde r
reprezintaÌ† rangul matriici A. Elementele nenule Ïƒi ale lui S sunt ordonate
descrescaÌ†tor Ïƒ1 â‰¥ Ïƒ2 â‰¥ ... â‰¥ Ïƒr > 0. Acestea se numesc valorile singulare ale
matricii A. Coloanele lui U reprezintaÌ† vectorii singulari la staÌ‚ngaÌ†, Ä±Ì‚n timp ce
coloanele lui v > vectorii singulari la dreapta.
    Valorile singulare ale lui A sunt raÌ†daÌ†cinile paÌ†trate ale valorilor proprii ale
matricii A> A.
    Descompunerea valorilor singulare reprezintaÌ† o schimbare de bazaÌ†. Privind
matricea A ca o transformare, spunem caÌ† ea transformaÌ† spat, iul Rn Ä±Ì‚n spat, iul
Rm . De aceea, o reprezentare utilaÌ† a matricii presupune gaÌ†sirea unei perechi
de baze pentru cele douaÌ† spat, ii. Matricile U s, i V constituie o alegere potrivitaÌ†
pentru aceaste baze, iar reprezentarea lui A Ä±Ì‚n raport cu acestea este o matrice
diagonalaÌ†.

1.1    Rangul unei matrici
Not, iunea de rang al unei matrici reprezintaÌ† numaÌ†rul de coloane liniar indepen-
dente. IÌ‚n practicaÌ†, pentru a calcula rangul se foloses, te observat, ia caÌ† acesta este
egal cu numaÌ†rul de valori singulare nenule.
     Prezent, a zgomotului Ä±Ì‚n date poate masca rangul real al unei matrici. Fie A âˆˆ
RmÃ—n o matrice de rang nemaximal r, cu r < min(m, n). Prin introducerea de
variat, ii mici, zgomotul perturbaÌ† liniaritatea coloanelor din A, faÌ†caÌ‚nd ca aceasta
saÌ† aibaÌ† rang maxim. Prezent, a zgomotului poate fi evaluataÌ† din valorile singulare
ale matricii. Valorile Ïƒi <  pot fi considerate neglijabile, ele corespunzaÌ‚nd
zgomotului. Valoarea lui  poate fi aleasaÌ† empiric.



                                           1
                  Figura 1: Dimensiunea datelor poate fi redusaÌ†.


    Observat, ia de mai sus duce la o altaÌ† aplicat, ie a SVD: aproximarea de rang
mic a unei matrici. Aceasta poate fi vaÌ†zutaÌ† ca o compresie a informat, iei din
matricea A avaÌ‚nd rang r s, i presupune aproximarea matricii prin trunchierea
valorilor singulare. Numim Ak o aproximare de rang k a lui A, cu k < r
                     k
                     X
              Ak =         Ïƒj uj vj> = U [:, 1 : k]S[1 : k, 1 : k]V [:, 1 : k]>       (2)
                     j=1

    Matricea Ak va cont, ine doar informat, ia importantaÌ† din A.


2     Analiza componentelor principale
Sect, iunea aceasta prezintaÌ† motivat, ia ultimei afirmat, ii de mai sus. Semnalele
Ä±Ì‚ntaÌ‚lnite Ä±Ì‚n practicaÌ† pot avea dimensiune mare, Ä±Ì‚nsaÌ† o parte din informat, ia
cont, inutaÌ† Ä±Ì‚n ele poate fi redundantaÌ† sau nesemnificativaÌ†. Aceasta Ä±Ì‚nseamnaÌ†
caÌ† ele pot fi aproximate cu semnale de dimensiune mai micaÌ†, faÌ†raÌ† a pierde
informat, ie relevantaÌ† (pentru aplicat, ia Ä±Ì‚n cauzaÌ†). O astfel de reprezentare are s, i
avantajul unui cost de calcul mai mic Ä±Ì‚n rezolvarea problemelor cu setul respectiv
de date.
     Figura 1 prezintaÌ† o astfel de situat, ie. Cu toate caÌ† datele au trei dimensiuni,
se observaÌ† caÌ† ele pot fi aproximate Ä±Ì‚n douaÌ† dimensiuni, deoarece variat, ia pe axa
z este nesemnificativaÌ† (Ä±Ì‚n raport cu variat, ia pe celelalte douaÌ† axe).
     Analiza componentelor principale (Principal Component Analysis - PCA)
este un algoritm de reducere a dimensiunii semnalelor ce foloses, te principiul
variant, ei maxime. Ne dorim saÌ† ret, inem din date doar traÌ†saÌ†turile semnificative.
Prin urmare vom caÌ†uta direct, iile pe care variant, a este mare s, i le vom elimina


                                              2
pe cele Ä±Ì‚n care datele au variant, aÌ† micaÌ†. PCA gaÌ†ses, te aceste direct, ii, numite
componente principale. Prima astfel de direct, ie este cea care minimizeazaÌ† media
paÌ†tratelor distant, elor de la puncte la acea dreaptaÌ†. UrmaÌ†toarea direct, ie este
aleasaÌ† extraÌ†gaÌ‚nd in matricea init, ialaÌ† contribut, ia primei direct, ii s, i calculul noii
drepte care minimizeazaÌ† media paÌ†tratelor distant, elor.
     AceastaÌ† proceduraÌ† este echivalentaÌ† cu calculul descompunerii valorilor sin-
gulare ale matricii A, deci cu descompunerea valorilor proprii ale lui A> A.
Componentele principale sunt vectorii proprii ai A> A. Pentru reducerea di-
mensiunii este suficientaÌ† deci alegerea unui numaÌ†r p de vectori proprii.
     Pentru a calcula PCA este necesaraÌ† o etapaÌ† preliminaraÌ† de centrare a date-
lor. AceastaÌ† operat, ie presupune scaÌ†derea din fiecare coloanaÌ† a mediei respectivei
coloane, astfel Ä±Ì‚ncaÌ‚t fiecare nouaÌ† coloanaÌ† are medie 0. O altaÌ† etapaÌ† de preproce-
sare, utilaÌ† atunci caÌ‚nd variat, iile coloanelor diferaÌ† semnificativ (spre exemplu da-
toritaÌ† faptului caÌ† reprezintaÌ† traÌ†saÌ†turi ale semnalului ce corespund unor maÌ†rimi
fizice diferite ca scalaÌ†) este operat, ia de standardizare. Pentru aceasta, fiecare
coloanaÌ† se Ä±Ì‚mparte la deviat, ia standard ale elementelor coloanei.


3     Ghid Python
Pentru a rezolva exercit, iile din laboratorul de astaÌ†zi, avet, i nevoie de bibliotecile
numpy, scipy s, i pandas, modulele random.sample, sklearn.decomposition.PCA
matplotlib.image s, i matplotlib.pyplot.

Pentru a calcula rangul unei matrici folosit, i numpy.linalg.matrix_rank(A).

Pentru a selecta aleator un numaÌ†r de k elemente dintr-un s, ir crescaÌ†tor de nu-
mere [1 : n], putet, i folosi random.sample(range(n),k).

Pentru a crea un zgomot Gaussian de medie m s, i dispersie d, folosit, i
numpy.random.normal(m,d,size), unde size reprezintaÌ† dimensiunea vectoru-
lui/matricii.

Pentru a calcula descopunerea valorilor singulare pentru o matrice, utilizat, i
 U, S, V = numpy.linalg.svd(A).
Funct, ia genereazaÌ† matricea V deja transpusaÌ†.

Pentru a Ä±Ì‚ncaÌ†rca o imagine utilizat, i matplotlib.image.imread(nume_imagine).
Pentru a afis, a o imagine salvataÌ† Ä±Ì‚n matricea A, folosit, i
matplotlibpyplot.imshow(A).

Pentru a obt, ine o matrice diagonalaÌ† dintr-un vector, numpy.diag(A).

Pentru a realiza reducerea dimensionalaÌ† a unui set de date X cu algoritmul
PCA, utilizat, i urmaÌ†toarele instruct, iuni, dupaÌ† ce at, i Ä±Ì‚ncaÌ†rcat modulul
sklearn.decomposition.PCA


                                              3
pca = PCA(n_components=comp)
    components = pca.fit_transform(X)
alegaÌ‚nd un numaÌ†r comp de componente relevant pentru dimensiunea semnale-
lor. Variabila components va cont, ine, pe coloane, direct, iile principale ale X.

Pentru a importa un fis, ier .csv Ä±Ì‚n format pandas dintr-o adresaÌ† url, utilizat, i
data = pandas.read_csv(â€™https://example.com/â€™).


4      Exercit, ii
    1. IÌ‚n Sect, iunea 1.1 se ment, ioneazaÌ† faptul caÌ† prezent, a zgomotului poate as-
       cunde rangul real al unei matrici. Testat, i aplicabilitatea SVD Ä±Ì‚n determi-
       narea rangului.
        (a) Creat, i o matrice aleatoare A âˆˆ RmÃ—r , unde m = 10 s, i r = 4.
            Calculat, i rangul matricii.
        (b) AdaÌ†ugat, i lui A un numaÌ†r de 4 coloane liniar dependente astfel Ä±Ì‚ncaÌ‚t
            noua matrice va avea dimensiunea A âˆˆ RmÃ—n , cu n = 8. Pentru a
            crea noile coloane, luat, i o combinat, ie liniaraÌ† de c = 3 coloane deja
            existente Ä±Ì‚n A. At, i obt, inut astfel o matrice de rang nemaximal.
            Verificat, i, calculaÌ‚nd din nou rangul matricii.
        (c) AdaÌ†ugat, i la matricea obt, inutaÌ† anterior un zgomot Gaussian de medie
            0 s, i dispersie 0.2. Calculat, i rangul noii matrici.
        (d) Calculat, i descompunerea valorilor singulare pentru matricea de mai
            sus s, i afis, at, i valorile singulare. CaÌ‚te din aceste valori sunt neglijabile?
            Putet, i deduce rangul matricii neafectate de zgomot din aceste valori?
            Comentat, i.
    2. Comprimat, i o imagine folosind SVD.
        (a) IÌ‚ncaÌ†rcat, i o imagine oarecare (.bmp, .jpg etc) Ä±Ì‚ntr-o matrice s, i calculat, i
            SVD.
        (b) Aleget, i un rang k pentru care vret, i saÌ† obt, inet, i aproximarea matri-
            cii de mai sus, astfel Ä±Ì‚ncaÌ‚t k < min(m, n), unde m s, i n reprezintaÌ†
            dimensiunile matricii. Obt, inet, i aproximarea de rang k a matricii,
            trunchiind valorile singulare.
        (c) Vizualizat, i noua imagine.
        (d) Repetat, i pentru 2 âˆ’ 3 valori ale lui k alese Ä±Ì‚n funct, ie de dimensiunea
            imaginii, pentru a vedea gradul de compresie Ä±Ì‚n fiecare caz.
    3. Utilizat, i PCA pentru a reduce dimensiunea semnalelor din baza de date
       iris, disponibilaÌ† la adresa
       https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.
       Aleget, i numaÌ†rul de componente principale ncomponents = 2 s, i vizualizat, i
       noul set de date.


                                              4
